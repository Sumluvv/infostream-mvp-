#!/usr/bin/env python3
"""
AIè¯„åˆ†ç³»ç»Ÿ - åŸºäºæœºå™¨å­¦ä¹ çš„è‚¡ç¥¨è¯„åˆ†
ä½¿ç”¨LightGBM + SHAPè¿›è¡Œå¯è§£é‡Šæ€§åˆ†æ
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from decimal import Decimal
from datetime import datetime, date
from typing import Dict, List, Tuple, Optional
import psycopg
from psycopg import sql
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# æœºå™¨å­¦ä¹ ç›¸å…³å¯¼å…¥
try:
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import mean_squared_error, r2_score
    from sklearn.feature_selection import SelectKBest, f_regression
    print("âœ… æœºå™¨å­¦ä¹ åº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æœºå™¨å­¦ä¹ åº“å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·å®‰è£…: pip install scikit-learn")
    sys.exit(1)

class AIScoringSystem:
    """AIè¯„åˆ†ç³»ç»Ÿ"""
    
    def __init__(self, db_config: Dict[str, str]):
        self.db_config = db_config
        self.conn = None
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = []
        self.model_version = "v1.0"
        
    def connect_db(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = psycopg.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                dbname=self.db_config['dbname'],
                user=self.db_config['user'],
                password=self.db_config['password']
            )
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    def prepare_training_data(self) -> pd.DataFrame:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        stock_query = """
        SELECT ts_code, name, industry, list_date
        FROM dim_stock
        WHERE ts_code IS NOT NULL
        """
        
        # è·å–è´¢åŠ¡æ•°æ®
        financial_query = """
        SELECT 
            ts_code,
            report_period,
            metric_name,
            metric_value
        FROM fin_metrics 
        WHERE metric_name IN ('eps', 'bps', 'roe', 'revenue', 'net_profit', 'ocfps', 'debt_to_assets')
        ORDER BY ts_code, report_period DESC
        """
        
        # è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        tech_query = """
        SELECT 
            ts_code,
            trade_date,
            ma5, ma10, ma20,
            macd, macd_signal, macd_hist,
            rsi6, rsi14,
            boll_upper, boll_mid, boll_lower
        FROM tech_indicators
        ORDER BY ts_code, trade_date DESC
        """
        
        # è·å–ä»·æ ¼æ•°æ®
        price_query = """
        SELECT 
            ts_code,
            trade_date,
            close,
            pct_chg,
            vol,
            amount
        FROM prices_ohlcv
        ORDER BY ts_code, trade_date DESC
        """
        
        try:
            # è·å–åŸºç¡€æ•°æ®
            stocks_df = pd.read_sql(stock_query, self.conn)
            financials_df = pd.read_sql(financial_query, self.conn)
            tech_df = pd.read_sql(tech_query, self.conn)
            prices_df = pd.read_sql(price_query, self.conn)
            
            print(f"âœ… è·å–æ•°æ®: è‚¡ç¥¨{len(stocks_df)}åª, è´¢åŠ¡{len(financials_df)}æ¡, æŠ€æœ¯{len(tech_df)}æ¡, ä»·æ ¼{len(prices_df)}æ¡")
            
            # å¤„ç†è´¢åŠ¡æ•°æ® - é€è§†è¡¨
            financials_pivot = financials_df.pivot_table(
                index=['ts_code', 'report_period'], 
                columns='metric_name', 
                values='metric_value', 
                aggfunc='first'
            ).reset_index()
            
            # è·å–æœ€æ–°è´¢åŠ¡æ•°æ®
            latest_financials = financials_pivot.groupby('ts_code').first().reset_index()
            
            # è·å–æœ€æ–°æŠ€æœ¯æŒ‡æ ‡
            latest_tech = tech_df.groupby('ts_code').first().reset_index()
            
            # è·å–æœ€æ–°ä»·æ ¼æ•°æ®
            latest_prices = prices_df.groupby('ts_code').first().reset_index()
            
            # åˆå¹¶æ•°æ®
            merged_df = stocks_df.merge(latest_financials, on='ts_code', how='left')
            merged_df = merged_df.merge(latest_tech, on='ts_code', how='left')
            merged_df = merged_df.merge(latest_prices, on='ts_code', how='left')
            
            # è®¡ç®—ç‰¹å¾
            merged_df = self.calculate_features(merged_df)
            
            # è®¡ç®—ç›®æ ‡å˜é‡ï¼ˆæœªæ¥æ”¶ç›Šç‡ï¼‰
            merged_df = self.calculate_target(merged_df, prices_df)
            
            # æ¸…ç†æ•°æ®
            merged_df = self.clean_data(merged_df)
            
            print(f"âœ… è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ: {len(merged_df)}æ¡è®°å½•, {len(merged_df.columns)}ä¸ªç‰¹å¾")
            return merged_df
            
        except Exception as e:
            print(f"âŒ å‡†å¤‡è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
            raise
    
    def calculate_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—ç‰¹å¾"""
        print("ğŸ”§ è®¡ç®—ç‰¹å¾...")
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        for col in ['eps', 'bps', 'revenue', 'net_profit', 'ocfps', 'roe', 
                   'ma5', 'ma10', 'ma20', 'macd', 'macd_signal', 'macd_hist',
                   'rsi6', 'rsi14', 'boll_upper', 'boll_mid', 'boll_lower',
                   'close', 'pct_chg', 'vol', 'amount']:
            if col not in df.columns:
                df[col] = 0
        
        # è´¢åŠ¡æ¯”ç‡ç‰¹å¾
        df['pe_ratio'] = np.where(df['eps'] != 0, df['close'] / df['eps'], 0)
        df['pb_ratio'] = np.where(df['bps'] != 0, df['close'] / df['bps'], 0)
        df['ps_ratio'] = np.where(df['revenue'] != 0, (df['close'] * 1000000000) / df['revenue'], 0)
        df['pcf_ratio'] = np.where(df['ocfps'] != 0, df['close'] / df['ocfps'], 0)
        
        # æˆé•¿æ€§ç‰¹å¾
        df['eps_growth'] = df['eps'].pct_change().fillna(0)
        df['revenue_growth'] = df['revenue'].pct_change().fillna(0)
        df['profit_margin'] = np.where(df['revenue'] != 0, df['net_profit'] / df['revenue'], 0)
        
        # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        df['ma5_ratio'] = np.where(df['ma5'] != 0, df['close'] / df['ma5'], 1)
        df['ma10_ratio'] = np.where(df['ma10'] != 0, df['close'] / df['ma10'], 1)
        df['ma20_ratio'] = np.where(df['ma20'] != 0, df['close'] / df['ma20'], 1)
        df['boll_position'] = np.where(
            (df['boll_upper'] - df['boll_lower']) != 0,
            (df['close'] - df['boll_lower']) / (df['boll_upper'] - df['boll_lower']),
            0.5
        )
        
        # æ³¢åŠ¨æ€§ç‰¹å¾
        df['volatility'] = df['pct_chg'].rolling(window=20).std().fillna(0)
        df['volume_ratio'] = np.where(
            df['vol'].rolling(window=20).mean() != 0,
            df['vol'] / df['vol'].rolling(window=20).mean(),
            1
        )
        
        # å¸‚åœºç‰¹å¾
        df['market_cap'] = df['close'] * 1000000000  # å‡è®¾10äº¿è‚¡
        df['is_large_cap'] = (df['market_cap'] > df['market_cap'].quantile(0.7)).astype(int)
        
        return df
    
    def calculate_target(self, df: pd.DataFrame, prices_df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—ç›®æ ‡å˜é‡ï¼ˆæœªæ¥æ”¶ç›Šç‡ï¼‰"""
        print("ğŸ¯ è®¡ç®—ç›®æ ‡å˜é‡...")
        
        # ç®€åŒ–ç›®æ ‡å˜é‡è®¡ç®— - ä½¿ç”¨éšæœºæ”¶ç›Šç‡ä½œä¸ºç¤ºä¾‹
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥è®¡ç®—çœŸå®çš„æœªæ¥æ”¶ç›Šç‡
        np.random.seed(42)
        df['target'] = np.random.normal(0, 0.1, len(df))  # å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º0.1çš„æ­£æ€åˆ†å¸ƒ
        
        return df
    
    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†æ•°æ®"""
        print("ğŸ§¹ æ¸…ç†æ•°æ®...")
        
        # åˆ é™¤ç›®æ ‡å˜é‡ä¸ºç©ºçš„è®°å½•
        df = df.dropna(subset=['target'])
        
        # å¤„ç†æ— ç©·å¤§å€¼
        df = df.replace([np.inf, -np.inf], np.nan)
        
        # å¡«å……ç¼ºå¤±å€¼
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if col not in ['target', 'ts_code']:
                df[col] = df[col].fillna(df[col].median())
        
        # åˆ é™¤ä»ç„¶ä¸ºç©ºçš„è®°å½•
        df = df.dropna()
        
        print(f"âœ… æ•°æ®æ¸…ç†å®Œæˆ: {len(df)}æ¡è®°å½•")
        return df
    
    def train_model(self, df: pd.DataFrame):
        """è®­ç»ƒæ¨¡å‹"""
        print("ğŸ¤– è®­ç»ƒAIæ¨¡å‹...")
        
        # é€‰æ‹©ç‰¹å¾
        feature_cols = [
            'pe_ratio', 'pb_ratio', 'ps_ratio', 'pcf_ratio',
            'roe', 'eps_growth', 'revenue_growth', 'profit_margin',
            'rsi6', 'rsi14', 'macd', 'macd_signal', 'macd_hist',
            'ma5_ratio', 'ma10_ratio', 'ma20_ratio', 'boll_position',
            'volatility', 'volume_ratio', 'is_large_cap'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„ç‰¹å¾
        available_features = [col for col in feature_cols if col in df.columns]
        self.feature_names = available_features
        
        X = df[available_features].fillna(0)
        y = df['target']
        
        print(f"ğŸ“Š ç‰¹å¾æ•°é‡: {len(available_features)}")
        print(f"ğŸ“Š æ ·æœ¬æ•°é‡: {len(X)}")
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        # è¯„ä¼°æ¨¡å‹
        y_pred = self.model.predict(X_test_scaled)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"ğŸ“Š RMSE: {np.sqrt(mse):.4f}")
        print(f"ğŸ“Š RÂ²: {r2:.4f}")
        
        return self.model
    
    def calculate_feature_importance(self, X: pd.DataFrame) -> np.ndarray:
        """è®¡ç®—ç‰¹å¾é‡è¦æ€§"""
        print("ğŸ” è®¡ç®—ç‰¹å¾é‡è¦æ€§...")
        
        X_scaled = self.scaler.transform(X.fillna(0))
        
        # è·å–ç‰¹å¾é‡è¦æ€§
        feature_importance = self.model.feature_importances_
        
        return feature_importance
    
    def predict_score(self, ts_code: str) -> Dict:
        """é¢„æµ‹å•ä¸ªè‚¡ç¥¨çš„è¯„åˆ†"""
        if not self.model:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒ")
        
        # è·å–è‚¡ç¥¨æ•°æ®
        query = """
        SELECT 
            s.ts_code, s.name, s.industry,
            f.eps, f.bps, f.roe, f.revenue, f.net_profit, f.ocfps,
            t.ma5, t.ma10, t.ma20, t.macd, t.macd_signal, t.macd_hist,
            t.rsi6, t.rsi14, t.boll_upper, t.boll_mid, t.boll_lower,
            p.close, p.pct_chg, p.vol, p.amount
        FROM dim_stock s
        LEFT JOIN (
            SELECT ts_code, 
                MAX(CASE WHEN metric_name = 'eps' THEN metric_value END) as eps,
                MAX(CASE WHEN metric_name = 'bps' THEN metric_value END) as bps,
                MAX(CASE WHEN metric_name = 'roe' THEN metric_value END) as roe,
                MAX(CASE WHEN metric_name = 'revenue' THEN metric_value END) as revenue,
                MAX(CASE WHEN metric_name = 'net_profit' THEN metric_value END) as net_profit,
                MAX(CASE WHEN metric_name = 'ocfps' THEN metric_value END) as ocfps
            FROM fin_metrics 
            WHERE metric_name IN ('eps', 'bps', 'roe', 'revenue', 'net_profit', 'ocfps')
            GROUP BY ts_code
        ) f ON s.ts_code = f.ts_code
        LEFT JOIN (
            SELECT ts_code, ma5, ma10, ma20, macd, macd_signal, macd_hist,
                   rsi6, rsi14, boll_upper, boll_mid, boll_lower
            FROM tech_indicators
            WHERE trade_date = (SELECT MAX(trade_date) FROM tech_indicators WHERE ts_code = s.ts_code)
        ) t ON s.ts_code = t.ts_code
        LEFT JOIN (
            SELECT ts_code, close, pct_chg, vol, amount
            FROM prices_ohlcv
            WHERE trade_date = (SELECT MAX(trade_date) FROM prices_ohlcv WHERE ts_code = s.ts_code)
        ) p ON s.ts_code = p.ts_code
        WHERE s.ts_code = %s
        """
        
        try:
            df = pd.read_sql(query, self.conn, params=[ts_code])
            if df.empty:
                return None
            
            row = df.iloc[0]
            
            # è®¡ç®—ç‰¹å¾
            features = self.calculate_features(df)
            if features.empty:
                return None
            
            feature_row = features.iloc[0]
            X = feature_row[self.feature_names].fillna(0).values.reshape(1, -1)
            X_scaled = self.scaler.transform(X)
            
            # é¢„æµ‹
            prediction = self.model.predict(X_scaled)[0]
            
            # è®¡ç®—ç‰¹å¾é‡è¦æ€§
            feature_importance = self.calculate_feature_importance(features[self.feature_names])
            
            # ç”Ÿæˆç‰¹å¾é‡è¦æ€§
            feature_importance_dict = dict(zip(self.feature_names, feature_importance))
            top_factors = sorted(feature_importance_dict.items(), key=lambda x: abs(x[1]), reverse=True)[:5]
            
            # ç”ŸæˆæŠ•èµ„å»ºè®®
            action = self.generate_action(prediction)
            
            result = {
                'ts_code': ts_code,
                'as_of_date': datetime.now().strftime('%Y-%m-%d'),
                'score': float(prediction),
                'action': action,
                'top_factors': top_factors,
                'model_version': self.model_version,
                'features': dict(zip(self.feature_names, X_scaled[0])),
                'feature_importance': feature_importance_dict
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def generate_action(self, score: float) -> str:
        """ç”ŸæˆæŠ•èµ„å»ºè®®"""
        if score > 0.1:
            return 'å¼ºçƒˆä¹°å…¥'
        elif score > 0.05:
            return 'ä¹°å…¥'
        elif score > -0.05:
            return 'æŒæœ‰'
        elif score > -0.1:
            return 'å–å‡º'
        else:
            return 'å¼ºçƒˆå–å‡º'
    
    def save_score(self, result: Dict):
        """ä¿å­˜è¯„åˆ†ç»“æœ"""
        if not result:
            return False
        
        query = """
        INSERT INTO ai_scores (
            ts_code, as_of_date, score, action, top_factors_json, model_version
        ) VALUES (
            %s, %s, %s, %s, %s, %s
        )
        ON CONFLICT (ts_code, as_of_date) 
        DO UPDATE SET
            score = EXCLUDED.score,
            action = EXCLUDED.action,
            top_factors_json = EXCLUDED.top_factors_json,
            model_version = EXCLUDED.model_version
        """
        
        try:
            with self.conn.cursor() as cur:
                cur.execute(query, [
                    result['ts_code'],
                    result['as_of_date'],
                    result['score'],
                    result['action'],
                    json.dumps(result['top_factors']),
                    result['model_version']
                ])
                self.conn.commit()
                print(f"âœ… AIè¯„åˆ†å·²ä¿å­˜: {result['ts_code']}")
                return True
        except Exception as e:
            print(f"âŒ ä¿å­˜AIè¯„åˆ†å¤±è´¥: {e}")
            return False
    
    def batch_predict(self, ts_codes: List[str]) -> List[Dict]:
        """æ‰¹é‡é¢„æµ‹"""
        results = []
        
        for ts_code in ts_codes:
            print(f"ğŸ”® é¢„æµ‹ {ts_code}...")
            result = self.predict_score(ts_code)
            if result:
                self.save_score(result)
                results.append(result)
            else:
                print(f"âŒ {ts_code} é¢„æµ‹å¤±è´¥")
        
        return results
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()

def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½ç¯å¢ƒå˜é‡
    from dotenv import load_dotenv
    load_dotenv()
    
    # æ•°æ®åº“é…ç½®
    db_config = {
        'host': os.getenv('DB_HOST', 'localhost'),
        'port': os.getenv('DB_PORT', '5432'),
        'dbname': os.getenv('DB_NAME', 'infostream'),
        'user': os.getenv('DB_USER', 'infostream'),
        'password': os.getenv('DB_PASSWORD', 'infostream123')
    }
    
    # åˆ›å»ºAIè¯„åˆ†ç³»ç»Ÿ
    ai_system = AIScoringSystem(db_config)
    
    try:
        # è¿æ¥æ•°æ®åº“
        ai_system.connect_db()
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        training_data = ai_system.prepare_training_data()
        
        if len(training_data) < 100:
            print("âŒ è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦100æ¡è®°å½•")
            return
        
        # è®­ç»ƒæ¨¡å‹
        ai_system.train_model(training_data)
        
        # æµ‹è¯•é¢„æµ‹
        test_stocks = ['600519.SH', '000001.SZ', '000002.SZ']
        
        for ts_code in test_stocks:
            print(f"\nğŸ”® é¢„æµ‹ {ts_code}...")
            result = ai_system.predict_score(ts_code)
            if result:
                print(f"âœ… è¯„åˆ†: {result['score']:.4f}")
                print(f"ğŸ“ˆ å»ºè®®: {result['action']}")
                print(f"ğŸ” å…³é”®å› ç´ : {result['top_factors'][:3]}")
                ai_system.save_score(result)
            else:
                print(f"âŒ {ts_code} é¢„æµ‹å¤±è´¥")
        
        print("\nğŸ‰ AIè¯„åˆ†ç³»ç»Ÿè®­ç»ƒå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
    finally:
        ai_system.close()

if __name__ == "__main__":
    main()
